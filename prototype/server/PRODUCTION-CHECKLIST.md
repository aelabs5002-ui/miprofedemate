# ‚úÖ CHECKLIST DE PRODUCCI√ìN - Backend Tutor√≠a Matem√°tica IA

## üìã Pre-Deploy Verification

### Backend Readiness
- [x] `index.js` escucha en `process.env.PORT` (l√≠nea 11)
- [x] `package.json` tiene script `"start": "node index.js"`
- [x] No hay paths hardcodeados (todo usa variables de entorno)
- [x] CORS configurable con `FRONTEND_ORIGIN`
- [x] Health check implementado en `/health`
- [x] Manejo de errores de OpenAI (401, 429, 500)
- [x] Logs informativos en consola
- [x] Dependencies instaladas: express, cors, dotenv, openai

### C√≥digo Listo
- [x] Prompts P01 y P07 implementados en `/prompts/tutor.js`
- [x] Endpoint `/api/tutor/respond` funcional
- [x] Validaci√≥n de inputs en endpoint
- [x] nextAction basado en contenido de respuesta IA
- [x] Fallback local en frontend si backend no disponible

---

## üöÄ Deploy en Render

### Configuraci√≥n del Servicio
- [ ] Web Service creado en Render
- [ ] Repositorio conectado
- [ ] Root Directory: `prototype/server` ‚ö†Ô∏è
- [ ] Build Command: `npm install`
- [ ] Start Command: `npm start`
- [ ] Plan seleccionado (Free o Starter)

### Variables de Entorno
- [ ] `OPENAI_API_KEY` configurada (sk-proj-...)
- [ ] `NODE_ENV` = `production`
- [ ] `FRONTEND_ORIGIN` configurada (URL del frontend)
- [ ] `MODEL_NAME` = `gpt-4o-mini` (opcional, tiene default)
- [ ] ‚ö†Ô∏è NO setear `PORT` (Render lo asigna autom√°ticamente)

### Deploy Exitoso
- [ ] Logs muestran: "üöÄ Servidor corriendo en puerto XXXXX"
- [ ] Logs muestran: "üìä Modelo: gpt-4o-mini"
- [ ] Logs muestran: "üîë API Key configurada: ‚úÖ"
- [ ] Sin errores en los logs
- [ ] Estado del servicio: "Live" (verde)

---

## üß™ Testing Post-Deploy

### 1. Backend Health Check
- [ ] Abrir: `https://tu-backend.onrender.com/health`
- [ ] Respuesta incluye:
  - [ ] `"status": "ok"`
  - [ ] `"model": "gpt-4o-mini"`
  - [ ] `"uptime": <n√∫mero>`
  - [ ] `"timestamp": <ISO date>`
  - [ ] `"env": "production"`

### 2. Backend API Endpoint
- [ ] Test con curl o Postman:
  ```bash
  curl -X POST https://tu-backend.onrender.com/api/tutor/respond \
    -H "Content-Type: application/json" \
    -d '{"exercisePrompt":"2+2=?","studentAnswer":"4","attemptNumber":1,"mode":"text","hintAllowed":false}'
  ```
- [ ] Respuesta incluye:
  - [ ] `assistantText` (string con feedback)
  - [ ] `nextAction` ("retry", "hint", o "next")
  - [ ] `meta.tokensIn` (n√∫mero)
  - [ ] `meta.tokensOut` (n√∫mero)

### 3. Frontend Configuration
- [ ] Archivo `.env.production` creado en `/workspace/prototype`
- [ ] `VITE_API_URL` apunta a Render: `https://tu-backend.onrender.com`
- [ ] Frontend buildeado: `pnpm run build`
- [ ] Frontend desplegado (Vercel/Netlify/otro)

### 4. CORS Verification
- [ ] `FRONTEND_ORIGIN` en Render coincide con URL del frontend
- [ ] Abrir frontend desplegado
- [ ] Abrir DevTools ‚Üí Console
- [ ] NO hay errores CORS
- [ ] NO hay errores de red (Network tab)

### 5. Flujo Completo End-to-End
- [ ] Abrir frontend desplegado
- [ ] Navegar a pantalla "Misi√≥n"
- [ ] Click en "Empezar sesi√≥n"
- [ ] Pantalla C4 se carga correctamente
- [ ] Badge "ü§ñ Tutor IA activo" visible (NO "Modo offline")
- [ ] Responder un ejercicio
- [ ] Feedback del tutor IA aparece en <5 segundos
- [ ] Feedback usa lenguaje pedag√≥gico (no dice "incorrecto")
- [ ] nextAction controla botones correctamente:
  - [ ] "Siguiente" si respuesta correcta
  - [ ] "Enviar" si debe reintentar
- [ ] Completar ejercicio ‚Üí avanza al siguiente
- [ ] Completar todos ‚Üí vuelve a Misi√≥n

### 6. Fallback Local (Resiliencia)
- [ ] En Render Dashboard ‚Üí Suspend el servicio temporalmente
- [ ] Recargar frontend
- [ ] Empezar sesi√≥n
- [ ] Badge cambia a "Modo offline"
- [ ] Responder ejercicio
- [ ] Validaci√≥n local funciona (feedback gen√©rico)
- [ ] App NO se rompe
- [ ] En Render Dashboard ‚Üí Resume el servicio
- [ ] Recargar frontend
- [ ] Badge vuelve a "ü§ñ Tutor IA activo"

---

## üìä Monitoring & Maintenance

### Logs
- [ ] Revisar logs en Render Dashboard ‚Üí Logs
- [ ] Buscar errores o warnings
- [ ] Verificar que requests se registran:
  ```
  üìù Request: user=..., session=..., exercise=..., attempt=...
  ‚úÖ Response: XX tokens, XXXms, action=...
  ```

### Performance
- [ ] Primera request (cold start): <30 segundos
- [ ] Requests subsecuentes: <5 segundos
- [ ] Tokens por request: 150-300 (promedio)
- [ ] Costo por request: ~$0.00015 USD

### Alertas
- [ ] Configurar alertas en Render (opcional):
  - [ ] Deploy failed
  - [ ] Service down
  - [ ] High error rate

### OpenAI Usage
- [ ] Revisar uso en https://platform.openai.com/usage
- [ ] Verificar que no hay picos anormales
- [ ] Confirmar que hay cr√©ditos suficientes

---

## üêõ Troubleshooting Checklist

### Si Backend no responde:
- [ ] Verificar estado en Render Dashboard (debe ser "Live")
- [ ] Revisar logs para errores
- [ ] Verificar que OPENAI_API_KEY es v√°lida
- [ ] Verificar que Root Directory es correcto
- [ ] Intentar Manual Deploy

### Si hay errores CORS:
- [ ] Verificar que FRONTEND_ORIGIN est√° seteada
- [ ] Verificar que coincide EXACTAMENTE con URL del frontend
- [ ] NO incluir trailing slash en FRONTEND_ORIGIN
- [ ] Verificar que frontend usa la URL correcta de backend

### Si IA no responde:
- [ ] Verificar API key en OpenAI Dashboard
- [ ] Verificar que hay cr√©ditos disponibles
- [ ] Revisar logs para errores 401 o 429
- [ ] Test directo con curl al endpoint

### Si servicio se duerme (Free Plan):
- [ ] Es normal en Free Plan despu√©s de 15 min inactividad
- [ ] Primera request despertar√° el servicio (~30 seg)
- [ ] Considerar upgrade a Starter Plan ($7/mes) para 24/7

---

## üéØ Success Criteria

El deploy es exitoso cuando:

‚úÖ Backend responde `/health` con status 200
‚úÖ Backend responde `/api/tutor/respond` con feedback de IA
‚úÖ Frontend conecta sin errores CORS
‚úÖ Flujo completo funciona: Misi√≥n ‚Üí Sesi√≥n ‚Üí IA responde ‚Üí Avanza
‚úÖ Fallback local funciona si backend no disponible
‚úÖ Logs muestran requests exitosos
‚úÖ Costos est√°n dentro de lo esperado (~$0.00015/request)

---

## üìù Post-Deploy Actions

- [ ] Documentar URL del backend en README principal
- [ ] Compartir URL de producci√≥n con el equipo
- [ ] Configurar monitoreo (opcional: UptimeRobot, Pingdom)
- [ ] Configurar backups de variables de entorno
- [ ] Planear siguiente iteraci√≥n (m√°s ejercicios, persistencia, etc.)

---

## ‚úÖ CONFIRMACI√ìN FINAL

- [ ] **Backend listo para producci√≥n en Render** ‚úÖ
- [ ] **Frontend conectado y funcionando** ‚úÖ
- [ ] **IA respondiendo correctamente** ‚úÖ
- [ ] **Fallback local funciona** ‚úÖ
- [ ] **Documentaci√≥n completa** ‚úÖ

**Fecha de Deploy:** _________________

**URL Backend:** _________________

**URL Frontend:** _________________

**Deployed by:** _________________

---

üéâ **¬°Producci√≥n lista!** El sistema est√° funcionando end-to-end con IA en la nube.