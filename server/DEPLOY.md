# üöÄ GU√çA DE DEPLOY EN RENDER - Backend Tutor√≠a Matem√°tica IA

Esta gu√≠a detalla los pasos exactos para desplegar el backend en Render y conectarlo con el frontend.

## ‚úÖ Pre-requisitos

- Cuenta en [Render.com](https://render.com) (plan gratuito funciona)
- Repositorio Git con el c√≥digo (GitHub, GitLab, o Bitbucket)
- API Key de OpenAI v√°lida con cr√©ditos

---

## üì¶ PASO 1: Verificar Readiness del Backend

Antes de desplegar, confirma que el backend est√° listo:

‚úÖ **index.js escucha en `process.env.PORT`** (l√≠nea 11)
```javascript
const PORT = process.env.PORT || 3001;
```

‚úÖ **package.json tiene script "start"**
```json
"scripts": {
  "start": "node index.js"
}
```

‚úÖ **No hay dependencias locales hardcodeadas** - Todo usa variables de entorno

‚úÖ **CORS configurable** - Soporta `FRONTEND_ORIGIN` para producci√≥n

---

## üåê PASO 2: Crear Web Service en Render

### 2.1. Acceder a Render Dashboard
1. Ve a https://dashboard.render.com/
2. Click en **"New +"** (bot√≥n azul superior derecho)
3. Selecciona **"Web Service"**

### 2.2. Conectar Repositorio
1. Conecta tu cuenta de GitHub/GitLab/Bitbucket si a√∫n no lo has hecho
2. Busca y selecciona tu repositorio del proyecto
3. Click en **"Connect"**

### 2.3. Configurar el Servicio

Completa el formulario con estos valores EXACTOS:

| Campo | Valor |
|-------|-------|
| **Name** | `tutoria-matematica-api` (o el nombre que prefieras) |
| **Region** | Selecciona la m√°s cercana a tus usuarios |
| **Branch** | `main` (o tu rama principal) |
| **Root Directory** | `prototype/server` ‚ö†Ô∏è IMPORTANTE |
| **Environment** | `Node` |
| **Build Command** | `npm install` |
| **Start Command** | `npm start` |
| **Plan** | `Free` (o el plan que prefieras) |

‚ö†Ô∏è **CR√çTICO**: El **Root Directory** debe ser exactamente `prototype/server` para que Render encuentre el package.json correcto.

---

## üîê PASO 3: Configurar Variables de Entorno

En la secci√≥n **"Environment Variables"**, a√±ade estas variables:

### Variables Obligatorias:

| Key | Value | Descripci√≥n |
|-----|-------|-------------|
| `OPENAI_API_KEY` | `sk-proj-...` | Tu API key de OpenAI |
| `NODE_ENV` | `production` | Entorno de producci√≥n |
| `FRONTEND_ORIGIN` | `https://tu-frontend.vercel.app` | URL de tu frontend (cambiar despu√©s) |

‚ö†Ô∏è **NO SETEAR `PORT`** - Render lo asigna autom√°ticamente.

### C√≥mo a√±adir variables:
1. Click en **"Add Environment Variable"**
2. Ingresa **Key** y **Value**
3. Repite para cada variable
4. Click en **"Save Changes"**

---

## üöÄ PASO 4: Desplegar

1. Click en **"Create Web Service"** (bot√≥n azul al final)
2. Render comenzar√° el deploy autom√°ticamente
3. Espera 2-5 minutos mientras:
   - Clona el repositorio
   - Ejecuta `npm install`
   - Inicia el servidor con `npm start`

### Monitorear el Deploy:
- Ve a la pesta√±a **"Logs"** para ver el progreso en tiempo real
- Busca estos mensajes de √©xito:
  ```
  üöÄ Servidor corriendo en puerto XXXXX
  üìä Modelo: gpt-4o-mini
  üîë API Key configurada: ‚úÖ
  ```

### URL del Servicio:
Una vez desplegado, tu backend estar√° disponible en:
```
https://tutoria-matematica-api.onrender.com
```
(El nombre depende del que elegiste en el paso 2.3)

---

## üß™ PASO 5: Verificar el Deploy

### 5.1. Probar Health Check

Abre en tu navegador o usa curl:

```bash
curl https://tutoria-matematica-api.onrender.com/health
```

**Respuesta esperada:**
```json
{
  "status": "ok",
  "model": "gpt-4o-mini",
  "uptime": 123.45,
  "timestamp": "2024-01-15T10:30:45.123Z",
  "env": "production"
}
```

‚úÖ Si ves esta respuesta, el backend est√° funcionando correctamente.

### 5.2. Probar Endpoint del Tutor

```bash
curl -X POST https://tutoria-matematica-api.onrender.com/api/tutor/respond \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "test-user",
    "sessionId": "test-session",
    "exerciseId": "ej1",
    "grade": "1sec",
    "topic": "Ecuaciones lineales",
    "studentAnswer": "4",
    "attemptNumber": 1,
    "mode": "text",
    "exercisePrompt": "¬øCu√°nto es 2x + 3 = 11? Resuelve para x.",
    "hintAllowed": false
  }'
```

**Respuesta esperada:**
```json
{
  "assistantText": "¬°Muy bien! üéØ Has encontrado la respuesta correcta...",
  "nextAction": "next",
  "meta": {
    "tokensIn": 245,
    "tokensOut": 42,
    "responseTime": 1250,
    "model": "gpt-4o-mini"
  }
}
```

---

## üîó PASO 6: Conectar el Frontend

### 6.1. Actualizar FRONTEND_ORIGIN en Render

1. Ve a tu servicio en Render Dashboard
2. Click en **"Environment"** en el men√∫ lateral
3. Edita la variable `FRONTEND_ORIGIN`
4. Cambia el valor a la URL real de tu frontend:
   - Si usas Vercel: `https://tu-app.vercel.app`
   - Si usas Netlify: `https://tu-app.netlify.app`
   - Si usas otro: la URL correspondiente
5. Click en **"Save Changes"**
6. El servicio se reiniciar√° autom√°ticamente

### 6.2. Configurar Frontend (Vite)

En tu proyecto frontend (`/workspace/prototype`):

1. **Crear archivo `.env.production`:**
   ```bash
   cd /workspace/prototype
   touch .env.production
   ```

2. **A√±adir la URL del backend:**
   ```env
   VITE_API_URL=https://tutoria-matematica-api.onrender.com
   ```
   (Reemplaza con tu URL real de Render)

3. **Para desarrollo local, crear `.env.development`:**
   ```env
   VITE_API_URL=http://localhost:3001
   ```

4. **Build y deploy del frontend:**
   ```bash
   pnpm run build
   # Luego despliega la carpeta dist/ en Vercel/Netlify
   ```

---

## ‚úÖ PASO 7: Checklist de Pruebas Post-Deploy

Realiza estas pruebas en orden:

### 7.1. Backend Health Check
- [ ] Abrir `https://tu-backend.onrender.com/health`
- [ ] Verificar que responde con `status: "ok"`
- [ ] Verificar que `env: "production"`

### 7.2. Conectividad Frontend-Backend
- [ ] Abrir tu frontend desplegado
- [ ] Abrir DevTools ‚Üí Console
- [ ] Verificar que NO hay errores CORS
- [ ] Verificar que NO hay errores de conexi√≥n

### 7.3. Flujo Completo de IA
- [ ] Ir a la pantalla "Misi√≥n"
- [ ] Click en "Empezar sesi√≥n"
- [ ] Responder un ejercicio
- [ ] Verificar que aparece feedback del tutor IA
- [ ] Verificar que el badge "ü§ñ Tutor IA activo" est√° visible
- [ ] Verificar que NO aparece "Modo offline"

### 7.4. Fallback Local (Opcional)
- [ ] Detener temporalmente el backend en Render (Suspend)
- [ ] Recargar el frontend
- [ ] Empezar sesi√≥n
- [ ] Verificar que aparece "Modo offline"
- [ ] Verificar que la validaci√≥n local funciona
- [ ] Reactivar el backend (Resume)

---

## üêõ Troubleshooting

### Error: "Cannot GET /"
**Causa:** Render no encuentra el index.js
**Soluci√≥n:** Verifica que Root Directory sea `prototype/server`

### Error: "OPENAI_API_KEY no est√° configurada"
**Causa:** Variable de entorno no seteada
**Soluci√≥n:** Ve a Environment en Render y a√±ade la variable

### Error: CORS en el frontend
**Causa:** FRONTEND_ORIGIN no coincide con la URL del frontend
**Soluci√≥n:** Actualiza FRONTEND_ORIGIN con la URL exacta (sin trailing slash)

### Error 401 de OpenAI
**Causa:** API key inv√°lida o sin cr√©ditos
**Soluci√≥n:** Verifica tu API key en https://platform.openai.com/api-keys

### El servicio se duerme (Free Plan)
**Causa:** Render Free duerme servicios inactivos despu√©s de 15 min
**Soluci√≥n:** 
- Primera request ser√° lenta (~30 segundos)
- Considera upgrade a plan Starter ($7/mes) para 24/7 uptime
- O implementa un ping cada 10 minutos desde un cron job externo

---

## üí∞ Costos Estimados

### Render Free Plan:
- ‚úÖ 750 horas/mes gratis
- ‚úÖ Suficiente para MVP y testing
- ‚ö†Ô∏è Servicio se duerme tras 15 min de inactividad
- ‚ö†Ô∏è 100GB bandwidth/mes

### Render Starter Plan ($7/mes):
- ‚úÖ Servicio 24/7 sin dormir
- ‚úÖ 400GB bandwidth/mes
- ‚úÖ Mejor para producci√≥n

### OpenAI (gpt-4o-mini):
- ~$0.00015 por interacci√≥n
- 1000 interacciones ‚âà $0.15 USD
- Muy econ√≥mico para MVP

---

## üìù Comandos √ötiles

### Ver logs en tiempo real:
```bash
# Desde Render Dashboard ‚Üí Logs
# O usando Render CLI:
render logs -f tutoria-matematica-api
```

### Reiniciar el servicio:
```bash
# Desde Render Dashboard ‚Üí Manual Deploy ‚Üí Deploy latest commit
```

### Actualizar variables de entorno:
```bash
# Render Dashboard ‚Üí Environment ‚Üí Edit ‚Üí Save Changes
# El servicio se reinicia autom√°ticamente
```

---

## üéØ Resumen de URLs

| Servicio | URL | Prop√≥sito |
|----------|-----|-----------|
| Backend Health | `https://tu-backend.onrender.com/health` | Verificar estado |
| Backend API | `https://tu-backend.onrender.com/api/tutor/respond` | Endpoint principal |
| Frontend | `https://tu-frontend.vercel.app` | Aplicaci√≥n web |
| Render Dashboard | `https://dashboard.render.com` | Gesti√≥n del backend |
| OpenAI Dashboard | `https://platform.openai.com` | Gesti√≥n de API keys |

---

## ‚úÖ Confirmaci√≥n Final

Una vez completados todos los pasos:

- ‚úÖ Backend desplegado en Render
- ‚úÖ Health check responde correctamente
- ‚úÖ Variables de entorno configuradas
- ‚úÖ CORS configurado con FRONTEND_ORIGIN
- ‚úÖ Frontend conectado al backend
- ‚úÖ Flujo completo de IA funcionando
- ‚úÖ Fallback local funciona si backend no disponible

**üéâ ¬°Backend listo para producci√≥n en Render!**

---

## üìû Soporte

- **Render Docs:** https://render.com/docs
- **OpenAI Docs:** https://platform.openai.com/docs
- **Issues del Proyecto:** [Tu repositorio]/issues